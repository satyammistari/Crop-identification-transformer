#!/usr/bin/env python3
"""
AMPT Crop Identification from Satellite Image
Analyzes the provided satellite image to identify different crop types using the Enhanced AMPT model.
"""

import os
import sys
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from pathlib import Path

# Add src to path
sys.path.append('src')

# Import our Enhanced AMPT components
from models.enhanced_ampt_model import EnhancedAMPTModel
from utils.comprehensive_metrics import EnhancedAMPTMetrics
from data.enhanced_datamodule import EnhancedAgriFieldNetDataModule

class SatelliteImageCropIdentifier:
    """Complete pipeline for identifying crops in satellite imagery using Enhanced AMPT."""
    
    def __init__(self):
        """Initialize the crop identification system."""
        print("üåæ Initializing Enhanced AMPT Crop Identification System...")
        
        # Crop class mapping for AgriFieldNet dataset
        self.crop_classes = {
            0: "Background/Other",
            1: "Maize",
            2: "Wheat", 
            3: "Soybean",
            4: "Rice",
            5: "Cotton",
            6: "Barley"
        }
        
        # Color mapping for visualization
        self.crop_colors = {
            0: [64, 64, 64],      # Background - Dark Gray
            1: [255, 255, 0],     # Maize - Yellow
            2: [255, 165, 0],     # Wheat - Orange
            3: [0, 255, 0],       # Soybean - Green
            4: [0, 191, 255],     # Rice - Deep Sky Blue
            5: [255, 20, 147],    # Cotton - Deep Pink
            6: [139, 69, 19]      # Barley - Saddle Brown
        }
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üîß Using device: {self.device}")
        
        # Initialize model
        self.model = self._initialize_model()
        self.metrics = EnhancedAMPTMetrics(num_classes=7)
        
    def _initialize_model(self):
        """Initialize the Enhanced AMPT model."""
        print("üöÄ Loading Enhanced AMPT Model with innovations...")
        
        # Model configuration
        config = {
            'backbone': 'resnet50',
            'num_classes': 7,
            'hidden_dim': 256,
            'num_heads': 8,
            'dropout_rate': 0.1,
            'learning_rate': 0.001,
            'foundation_model_dim': 512
        }
        
        # Initialize model
        model = EnhancedAMPTModel(config)
        model.to(self.device)
        model.eval()
        
        print("‚úÖ Enhanced AMPT Model loaded successfully!")
        print(f"   - Cross-Modal Phenological Attention (CMPA): Enabled")
        print(f"   - Hierarchical Scale-Adaptive Fusion (HSAF): Enabled") 
        print(f"   - Foundation Model Adaptation (FMA): Enabled")
        
        return model
    
    def preprocess_satellite_image(self, image_path):
        """Preprocess satellite image for AMPT model."""
        print(f"üì° Processing satellite image: {image_path}")
        
        # Load image
        image = Image.open(image_path).convert('RGB')
        original_size = image.size
        print(f"   - Original image size: {original_size}")
        
        # Resize to model input size (512x512)
        target_size = (512, 512)
        image_resized = image.resize(target_size, Image.Resampling.LANCZOS)
        
        # Convert to numpy array and normalize
        image_array = np.array(image_resized).astype(np.float32) / 255.0
        
        # Create synthetic multi-modal data for demonstration
        # In real scenario, these would be actual SAR and weather data
        optical_data = torch.tensor(image_array).permute(2, 0, 1).unsqueeze(0)  # [1, 3, 512, 512]
        
        # Synthetic SAR data (2 channels)
        sar_data = torch.randn(1, 2, 512, 512) * 0.5 + 0.5
        
        # Synthetic weather data (10 features)
        weather_data = torch.randn(1, 10) * 0.5 + 0.5
        
        # Move to device
        optical_data = optical_data.to(self.device)
        sar_data = sar_data.to(self.device)
        weather_data = weather_data.to(self.device)
        
        print(f"   - Processed to size: {target_size}")
        print(f"   - Optical data shape: {optical_data.shape}")
        print(f"   - SAR data shape: {sar_data.shape}")
        print(f"   - Weather data shape: {weather_data.shape}")
        
        return {
            'optical': optical_data,
            'sar': sar_data,
            'weather': weather_data
        }, original_size, image_array
    
    def predict_crops(self, processed_data):
        """Predict crop types using Enhanced AMPT model."""
        print("üîç Running Enhanced AMPT crop identification...")
        
        with torch.no_grad():
            # Forward pass through Enhanced AMPT
            output = self.model(processed_data)
            
            # Get predictions
            if isinstance(output, dict):
                logits = output.get('logits', output.get('predictions', output))
            else:
                logits = output
            
            # Apply softmax to get probabilities
            probabilities = F.softmax(logits, dim=1)
            predictions = torch.argmax(probabilities, dim=1)
            
            print(f"   - Prediction shape: {predictions.shape}")
            print(f"   - Probability shape: {probabilities.shape}")
            
            return predictions, probabilities, logits
    
    def analyze_crop_distribution(self, predictions, probabilities):
        """Analyze the distribution of predicted crops."""
        print("üìä Analyzing crop distribution...")
        
        # Convert to numpy
        pred_np = predictions.cpu().numpy().flatten()
        prob_np = probabilities.cpu().numpy()
        
        # Calculate crop statistics
        unique_crops, counts = np.unique(pred_np, return_counts=True)
        total_pixels = len(pred_np)
        
        crop_stats = {}
        for crop_id, count in zip(unique_crops, counts):
            percentage = (count / total_pixels) * 100
            crop_name = self.crop_classes[crop_id]
            avg_confidence = np.mean(prob_np[0, crop_id]) * 100
            
            crop_stats[crop_id] = {
                'name': crop_name,
                'pixel_count': count,
                'percentage': percentage,
                'confidence': avg_confidence
            }
        
        # Sort by percentage
        sorted_stats = sorted(crop_stats.items(), key=lambda x: x[1]['percentage'], reverse=True)
        
        print("\nüåæ CROP IDENTIFICATION RESULTS:")
        print("=" * 50)
        for crop_id, stats in sorted_stats:
            print(f"{stats['name']:15} | {stats['percentage']:6.2f}% | Confidence: {stats['confidence']:5.1f}%")
        
        return crop_stats
    
    def create_visualization(self, predictions, original_image, crop_stats, save_path):
        """Create comprehensive visualization of crop identification results."""
        print("üé® Creating visualization...")
        
        # Convert predictions to color map
        pred_np = predictions.cpu().numpy().squeeze()
        height, width = pred_np.shape
        
        # Create colored prediction map
        colored_pred = np.zeros((height, width, 3), dtype=np.uint8)
        for crop_id, color in self.crop_colors.items():
            mask = pred_np == crop_id
            colored_pred[mask] = color
        
        # Create figure with subplots
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Enhanced AMPT Crop Identification Results', fontsize=16, fontweight='bold')
        
        # Original image
        axes[0, 0].imshow(original_image)
        axes[0, 0].set_title('Original Satellite Image', fontweight='bold')
        axes[0, 0].axis('off')
        
        # Prediction map
        axes[0, 1].imshow(colored_pred)
        axes[0, 1].set_title('Crop Classification Map', fontweight='bold')
        axes[0, 1].axis('off')
        
        # Crop distribution pie chart
        crop_names = []
        percentages = []
        colors = []
        
        for crop_id, stats in crop_stats.items():
            if stats['percentage'] > 1.0:  # Only show crops with >1% coverage
                crop_names.append(stats['name'])
                percentages.append(stats['percentage'])
                color_rgb = [c/255.0 for c in self.crop_colors[crop_id]]
                colors.append(color_rgb)
        
        axes[1, 0].pie(percentages, labels=crop_names, colors=colors, autopct='%1.1f%%', startangle=90)
        axes[1, 0].set_title('Crop Distribution', fontweight='bold')
        
        # Legend and statistics
        legend_text = "CROP IDENTIFICATION SUMMARY\\n"
        legend_text += "=" * 35 + "\\n"
        legend_text += f"Total Area Analyzed: {pred_np.size:,} pixels\\n"
        legend_text += f"Number of Crop Types: {len([s for s in crop_stats.values() if s['percentage'] > 1.0])}\\n\\n"
        
        legend_text += "DETECTED CROPS:\\n"
        legend_text += "-" * 35 + "\\n"
        
        for crop_id, stats in sorted(crop_stats.items(), key=lambda x: x[1]['percentage'], reverse=True):
            if stats['percentage'] > 1.0:
                legend_text += f"{stats['name']:12}: {stats['percentage']:5.1f}% (Conf: {stats['confidence']:4.1f}%)\\n"
        
        axes[1, 1].text(0.05, 0.95, legend_text, transform=axes[1, 1].transAxes, 
                       fontfamily='monospace', fontsize=10, verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        axes[1, 1].set_xlim(0, 1)
        axes[1, 1].set_ylim(0, 1)
        axes[1, 1].axis('off')
        axes[1, 1].set_title('Analysis Summary', fontweight='bold')
        
        # Save visualization
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"   - Visualization saved: {save_path}")
        
        return fig
    
    def identify_crops_in_image(self, image_path):
        """Complete pipeline to identify crops in satellite image."""
        print("\\n" + "=" * 60)
        print("üåæ ENHANCED AMPT CROP IDENTIFICATION PIPELINE")
        print("=" * 60)
        
        try:
            # Check if image exists
            if not os.path.exists(image_path):
                print(f"‚ùå Error: Image not found at {image_path}")
                return None
            
            # Step 1: Preprocess image
            processed_data, original_size, original_image = self.preprocess_satellite_image(image_path)
            
            # Step 2: Run prediction
            predictions, probabilities, logits = self.predict_crops(processed_data)
            
            # Step 3: Analyze results
            crop_stats = self.analyze_crop_distribution(predictions, probabilities)
            
            # Step 4: Create visualization
            output_dir = Path("outputs/crop_identification")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            viz_path = output_dir / "satellite_image_crop_analysis.png"
            self.create_visualization(predictions, original_image, crop_stats, viz_path)
            
            # Step 5: Save detailed results
            results_path = output_dir / "crop_identification_results.txt"
            self.save_detailed_results(crop_stats, results_path, image_path)
            
            print("\\n‚úÖ CROP IDENTIFICATION COMPLETED SUCCESSFULLY!")
            print(f"üìÅ Results saved in: {output_dir}")
            print(f"üñºÔ∏è  Visualization: {viz_path}")
            print(f"üìÑ Detailed report: {results_path}")
            
            return {
                'predictions': predictions,
                'probabilities': probabilities,
                'crop_stats': crop_stats,
                'visualization_path': viz_path,
                'results_path': results_path
            }
            
        except Exception as e:
            print(f"‚ùå Error during crop identification: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def save_detailed_results(self, crop_stats, save_path, image_path):
        """Save detailed analysis results to file."""
        with open(save_path, 'w') as f:
            f.write("ENHANCED AMPT CROP IDENTIFICATION RESULTS\\n")
            f.write("=" * 50 + "\\n\\n")
            f.write(f"Input Image: {image_path}\\n")
            f.write(f"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
            f.write(f"Model: Enhanced AMPT with CMPA, HSAF, and FMA innovations\\n\\n")
            
            f.write("CROP DISTRIBUTION ANALYSIS:\\n")
            f.write("-" * 30 + "\\n")
            
            total_pixels = sum(stats['pixel_count'] for stats in crop_stats.values())
            f.write(f"Total analyzed area: {total_pixels:,} pixels\\n\\n")
            
            for crop_id, stats in sorted(crop_stats.items(), key=lambda x: x[1]['percentage'], reverse=True):
                f.write(f"{stats['name']}:\\n")
                f.write(f"  Coverage: {stats['percentage']:.2f}% ({stats['pixel_count']:,} pixels)\\n")
                f.write(f"  Average Confidence: {stats['confidence']:.2f}%\\n\\n")
            
            f.write("\\nMODEL INNOVATIONS UTILIZED:\\n")
            f.write("-" * 30 + "\\n")
            f.write("‚úì Cross-Modal Phenological Attention (CMPA)\\n")
            f.write("‚úì Hierarchical Scale-Adaptive Fusion (HSAF)\\n")
            f.write("‚úì Foundation Model Adaptation (FMA)\\n")

def main():
    """Main execution function."""
    # Initialize the crop identifier
    identifier = SatelliteImageCropIdentifier()
    
    # Path to the input satellite image
    image_path = "input_satellite_image.png"
    
    # Run crop identification
    results = identifier.identify_crops_in_image(image_path)
    
    if results:
        print("\\nüéâ Crop identification completed! Check the outputs/crop_identification folder for detailed results.")
    else:
        print("\\n‚ùå Crop identification failed. Please check the error messages above.")

if __name__ == "__main__":
    # Add pandas import for timestamp
    import pandas as pd
    main()
